{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "# from wordcloud import WordCloud \n",
    "# from Semi_EM_NB import Semi_EM_MultinomialNB\n",
    "%run Semi_EM_NB.ipynb\n",
    "from os import path\n",
    "from PIL import Image\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(sentence):\n",
    "    result = ''\n",
    "    poster = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopword_set = set(stopwords.words('english'))\n",
    "    wordlist = re.sub(r\"\\n|(\\\\(.*?){)|}|[!$%^&*#()_+|~\\-={}\\[\\]:\\\";'<>?,.\\/\\\\]|[0-9]|[@]\", ' ', sentence) # remove punctuation\n",
    "    wordlist = re.sub('\\s+', ' ', wordlist) # remove extra space\n",
    "    wordlist_normal = [poster.stem(word.lower()) for word in wordlist.split()] # restore word to its original form (stemming)\n",
    "    wordlist_normal = [lemmatizer.lemmatize(word, pos='v') for word in wordlist_normal] # restore word to its root form (lemmatization)\n",
    "    wordlist_clean = [word for word in wordlist_normal if word not in stopword_set] # remove stopwords\n",
    "    result = ' '.join(wordlist_clean)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(clf, data_X, data_y, unlabeled=None, n_folds=5):\n",
    "    print('=' * 80)\n",
    "    print(\"Validation: \")\n",
    "    print(clf)\n",
    "    kf = StratifiedKFold(n_splits=n_folds)\n",
    "    start_time = time()\n",
    "    train_accuracies= list() # training accuracy\n",
    "    fold_count = 1\n",
    "    original_clf = deepcopy(clf)\n",
    "    for train_ids, valid_ids in kf.split(data_X, data_y):\n",
    "        cv_clf = deepcopy(original_clf)\n",
    "        print(\"Fold # %d\" % fold_count)\n",
    "        fold_count += 1\n",
    "        train_X, train_y, valid_X, valid_y = data_X[train_ids], data_y[train_ids], data_X[valid_ids], data_y[valid_ids]\n",
    "        if unlabeled==None:\n",
    "            cv_clf.fit(train_X, train_y)\n",
    "        else:\n",
    "            cv_clf.fit(train_X, train_y, unlabeled)\n",
    "        pred = cv_clf.predict(valid_X)\n",
    "        train_accuracies.append(metrics.accuracy_score(valid_y, pred))\n",
    "    train_time = time() - start_time\n",
    "    print(\"Validation time: %0.3f seconds\" % train_time)\n",
    "    print(\"Average training accuracy: %0.3f\" % np.mean(np.array(train_accuracies)))\n",
    "    return train_accuracies, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topK(classifier, vectorizer, categories, K=10):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    nrows, ncols = 5, 4\n",
    "#     fig, axes = plt.subplots(figsize=(50, 40), nrows=nrows, ncols=ncols)\n",
    "    #d = path.dirname(__file__)\n",
    "#     circle_mask = np.array(Image.open(path.join('./', \"circle.png\")))\n",
    "    for i, category in enumerate(categories):\n",
    "        topK = np.argsort(classifier.coef_[i])[-K:]\n",
    "        text = \" \".join(feature_names[topK])\n",
    "        print(\"%s: %s\" % (category, text))\n",
    "#         wordcloud = WordCloud(background_color=\"white\", mask=circle_mask).generate(text)\n",
    "#         axes[i//ncols, i%ncols].imshow(wordcloud, cmap=plt.cm.cool_r, interpolation='bilinear')\n",
    "#         axes[i//ncols, i%ncols].axis(\"off\")\n",
    "#         axes[i//ncols, i%ncols].set_title(category, fontweight=\"bold\", size=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:    15076\tTest set size:     3770\n"
     ]
    }
   ],
   "source": [
    "# Load data set with class labels and split into train and test set\n",
    "test_size_ratio = 0.2\n",
    "data_Xy = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True)\n",
    "category_names = data_Xy.target_names # text names of all categories\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_Xy.data, data_Xy.target, test_size=test_size_ratio, stratify=data_Xy.target)\n",
    "print(\"Training set size: %8d\\tTest set size: %8d\" % (len(train_X), len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess train and test text data\n",
    "train_X_clean = map(remove_noise, train_X)\n",
    "test_X_clean = map(remove_noise, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15076, 38677) (3770, 38677)\n"
     ]
    }
   ],
   "source": [
    "# Convert all text data into tf-idf vectors \n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=5, max_df=0.95, ngram_range=(1,2))\n",
    "# vectorizer = TfidfVectorizer()\n",
    "train_vec = vectorizer.fit_transform(train_X_clean)\n",
    "test_vec = vectorizer.transform(test_X_clean)\n",
    "print(train_vec.shape, test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1507, 38677) (13569, 38677)\n"
     ]
    }
   ],
   "source": [
    "# Divide train data set into labeled and unlabeled data sets\n",
    "split_ratio = 0.1 # labeled vs total(labeled+unlabeled)\n",
    "X_l, X_u, y_l, y_u = train_test_split(train_vec, train_y, train_size=split_ratio, stratify=train_y)\n",
    "print(X_l.shape, X_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Validation: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "Fold # 1\n",
      "Fold # 2\n",
      "Fold # 3\n",
      "Fold # 4\n",
      "Fold # 5\n",
      "Validation time: 0.150 seconds\n",
      "Average training accuracy: 0.589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5522875816993464,\n",
       "  0.6143790849673203,\n",
       "  0.6085526315789473,\n",
       "  0.5833333333333334,\n",
       "  0.5876288659793815],\n",
       " 0.15016531944274902)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation for Naive Bayes classifier \n",
    "# using labeled data set only\n",
    "nb_clf = MultinomialNB(alpha=1e-2)\n",
    "cross_validation(nb_clf, X_l, y_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Validation: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "Fold # 1\n",
      "Fold # 2\n",
      "Fold # 3\n",
      "Fold # 4\n",
      "Fold # 5\n",
      "Validation time: 112.902 seconds\n",
      "Average training accuracy: 0.664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6666666666666666,\n",
       "  0.6437908496732027,\n",
       "  0.6907894736842105,\n",
       "  0.6266666666666667,\n",
       "  0.6941580756013745],\n",
       " 112.90190744400024)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation for semisupervised EM Naive Bayes classifier \n",
    "# using both labeled and unlabeled data set\n",
    "em_nb_clf = Semi_EM_MultinomialNB(alpha=1e-2, tol=100, print_log_lkh=False) # semi supervised EM based Naive Bayes classifier\n",
    "cross_validation(em_nb_clf, X_l, y_l, X_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.61      0.42      0.50       160\n",
      "           comp.graphics       0.54      0.60      0.57       195\n",
      " comp.os.ms-windows.misc       0.59      0.53      0.56       197\n",
      "comp.sys.ibm.pc.hardware       0.53      0.53      0.53       196\n",
      "   comp.sys.mac.hardware       0.57      0.64      0.60       193\n",
      "          comp.windows.x       0.65      0.78      0.71       198\n",
      "            misc.forsale       0.77      0.63      0.69       195\n",
      "               rec.autos       0.64      0.63      0.63       198\n",
      "         rec.motorcycles       0.46      0.58      0.51       199\n",
      "      rec.sport.baseball       0.81      0.81      0.81       199\n",
      "        rec.sport.hockey       0.84      0.77      0.80       200\n",
      "               sci.crypt       0.67      0.72      0.69       198\n",
      "         sci.electronics       0.59      0.53      0.56       197\n",
      "                 sci.med       0.77      0.78      0.78       198\n",
      "               sci.space       0.76      0.62      0.68       197\n",
      "  soc.religion.christian       0.57      0.81      0.67       199\n",
      "      talk.politics.guns       0.50      0.51      0.51       182\n",
      "   talk.politics.mideast       0.63      0.77      0.69       188\n",
      "      talk.politics.misc       0.56      0.49      0.52       155\n",
      "      talk.religion.misc       0.45      0.19      0.27       126\n",
      "\n",
      "                accuracy                           0.63      3770\n",
      "               macro avg       0.63      0.62      0.61      3770\n",
      "            weighted avg       0.63      0.63      0.62      3770\n",
      "\n",
      "0.6278514588859416\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate original NB classifier using test data set\n",
    "nb_clf = MultinomialNB(alpha=1e-2).fit(X_l, y_l)\n",
    "pred = nb_clf.predict(test_vec)\n",
    "print(metrics.classification_report(test_y, pred, target_names=category_names))\n",
    "# pprint(metrics.confusion_matrix(test_Xy.target, pred))\n",
    "print(metrics.accuracy_score(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.66      0.33      0.44       160\n",
      "           comp.graphics       0.52      0.60      0.56       195\n",
      " comp.os.ms-windows.misc       0.72      0.58      0.64       197\n",
      "comp.sys.ibm.pc.hardware       0.60      0.62      0.61       196\n",
      "   comp.sys.mac.hardware       0.63      0.68      0.66       193\n",
      "          comp.windows.x       0.68      0.79      0.73       198\n",
      "            misc.forsale       0.81      0.63      0.71       195\n",
      "               rec.autos       0.69      0.72      0.71       198\n",
      "         rec.motorcycles       0.77      0.60      0.68       199\n",
      "      rec.sport.baseball       0.93      0.80      0.86       199\n",
      "        rec.sport.hockey       0.90      0.82      0.86       200\n",
      "               sci.crypt       0.80      0.78      0.79       198\n",
      "         sci.electronics       0.73      0.55      0.63       197\n",
      "                 sci.med       0.78      0.84      0.81       198\n",
      "               sci.space       0.80      0.74      0.77       197\n",
      "  soc.religion.christian       0.37      0.91      0.52       199\n",
      "      talk.politics.guns       0.61      0.76      0.68       182\n",
      "   talk.politics.mideast       0.73      0.80      0.76       188\n",
      "      talk.politics.misc       0.66      0.50      0.57       155\n",
      "      talk.religion.misc       0.73      0.13      0.22       126\n",
      "\n",
      "                accuracy                           0.67      3770\n",
      "               macro avg       0.71      0.66      0.66      3770\n",
      "            weighted avg       0.71      0.67      0.67      3770\n",
      "\n",
      "0.6740053050397878\n"
     ]
    }
   ],
   "source": [
    "# Evaluate semi-supervised EM NB classifier using test data set\n",
    "em_nb_clf = Semi_EM_MultinomialNB(alpha=1e-2, tol=100, print_log_lkh=False).fit(X_l, y_l, X_u)\n",
    "pred = em_nb_clf.predict(test_vec)\n",
    "print(metrics.classification_report(test_y, pred, target_names=category_names))\n",
    "# pprint(metrics.confusion_matrix(test_Xy.target, pred))\n",
    "print(metrics.accuracy_score(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: wa goal mean nicknam true read argument conner believ bobbi world ha doe religion moral belief theism bcci peopl atheism exist make atheist think whi post thi say god islam\n",
      "comp.graphics: print vesa hello ha comp color algorithm directori anyon comp graphic line help bite format veri mail know window viewer use thank program look ani tiff pleas thi graphic file imag\n",
      "comp.os.ms-windows.misc: product font zip help program manag nt desktop need thank set cica tri icon mode problem group card ax ax ax ani run program ms thi directori win use driver file window\n",
      "comp.sys.ibm.pc.hardware: like thi monitor doe anyon jumper buy control bu pleas motherboard video need dx video card help pc use pin modem ani thank work problem board scsi ide thi monitor drive card\n",
      "comp.sys.mac.hardware: upgrad thank machin quadra know powerbook ha disk centri extern buy mb problem ani instal lc drive processor doe anyon vram card simm use comput color mac monitor thi appl\n",
      "comp.windows.x: like help key work export support font sun code tar edu user file hp run program xterm ani hi sourc thank widget applic display use server motif thi pleas window\n",
      "misc.forsale: tape ega origin cassett adapt drive test ha pleas good disk make ask pay sne mail pc new thi use game manual modem sell box make offer ship includ offer sale\n",
      "rec.autos: std right look like auto europ come nissan use guess manual price think veri peopl make buy model dealer flat convert road ha gt altima engin wa thi drive car\n",
      "rec.motorcycles: say ha time year dod leave question right seat thi chase rider know otherwis look like drive think buy harley realli lean counterst yep bmw road wa motorcycl ride bike\n",
      "rec.sport.baseball: think season thi year win ball dodger run good know leagu fan field bat cub nl era pitch play pitcher ha yanke basebal thi wa stat game hi hit year team\n",
      "rec.sport.hockey: point lead sport canada hi period ha ulf think wing season say year player cherri score flyer shoot thi playoff roger pen leaf win goal wa play team hockey game\n",
      "sci.crypt: rsa make becaus clipper chip onli public messag know privaci clinton wiretap wa case ha ani agenc pgp secur peopl algorithm phone nsa use escrow govern clipper thi chip encrypt key\n",
      "sci.electronics: video input thing switch isbn pin audio time chip know batteri anyon line output current copi amp signal bulb cheap good like power wire build work thi uv circuit use\n",
      "sci.med: like health say pitt drug long gordon pitt edu gordon bank want geb diseas time test field infect peopl edu treat studi restaur medic use kidney caus effect wa thi food msg\n",
      "sci.space: lunar program scienc billion someth engin solar use new ha univers earth year nasa think assum time banner flight hst ani shuttl develop wa orbit launch like cost thi space\n",
      "soc.religion.christian: discuss bodi cathol testament faith christ resurrect marriag whi think book belief hell tomb truth hi ha say bibl peopl know sin heaven wa believ jesu church thi god christian\n",
      "talk.politics.guns: talk member atf start ha govern crime use law enforc ani burn think enforc state polit fbi kill cult nra make gun control firearm happen weapon right peopl wa thi law gun\n",
      "talk.politics.mideast: war serdar countri million armenia histori azeri hi state right jewish holocaust report nation turkey govern palestinian say thi jew turk kill peopl turkish wa arab isra israel muslim armenian\n",
      "talk.politics.misc: make post job congress like percent economi good men hostag ha clinton children vat tri support state koresh govern nation gay discrimin clayton right think say wa thi homosexu peopl\n",
      "talk.religion.misc: onli wrong point teach peopl teach jesu word know say believ fbi want creation cheer build evid thing love koresh god mani cathol kent mormon cheer kent bibl jesu wa thi christian\n"
     ]
    }
   ],
   "source": [
    "show_topK(nb_clf, vectorizer, category_names, K=30) # keywords for each class by original NB classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: definit becaus agre argument thing know ani doe statement word mean delet whi belief religion peopl make wa post believ atheism exist think object atheist islam moral say thi god\n",
      "comp.graphics: site anyon know inform edu softwar email appreci post color doe bite help window ftp convert mail look anyon gif know use program format pleas ani thi graphic thank imag file\n",
      "comp.os.ms-windows.misc: know tri ha edu font chang instal directori ms like mode zip disk os cica ani ftp card thank work version win problem run program thi use driver file window\n",
      "comp.sys.ibm.pc.hardware: isa port need buy pleas motherboard problem disk work driver ha video pc board know doe anyon monitor dx mb ani control thank thi ide use bu scsi drive card\n",
      "comp.sys.mac.hardware: quadra price speed buy new centri lc wa comput machin scsi mb disk work mhz ha thank doe card know simm ani problem monitor anyon use thi drive appl mac\n",
      "comp.windows.x: set client font like edu tri mail know anyon help doe code pleas problem work sun xterm file applic run ani display thank program widget motif server thi use window\n",
      "misc.forsale: make modem old card softwar pay box excel origin edu cd game use email make offer drive best offer disk ask mail new manual price condit includ pleas sell ship offer sale\n",
      "rec.autos: brake road tire sell wheel make model auto good dealer speed know price year oil new use mile think look ha ani ford like buy drive thi engin wa car\n",
      "rec.motorcycles: new time ani drive seat mile ha make good realli right think say car look road rider buy honda know helmet dog bmw like thi motorcycl dod wa ride bike\n",
      "rec.sport.baseball: sox score say like hitter time good brave leagu stat bat ball run fan ha season play think win pitcher player thi basebal hi hit pitch team year wa game\n",
      "rec.sport.hockey: detroit wing leagu watch like ranger shoot time pen ha bruin score nhl hi fan espn year think goal leaf win season thi playoff player hockey wa play team game\n",
      "sci.crypt: agenc wiretap say public clipper chip think onli messag crypto bite ani ha like wa law make peopl know escrow algorithm nsa secur phone govern use clipper chip thi encrypt key\n",
      "sci.electronics: time design ha radio input line anyon grind current make signal good wire need chip know wa voltag look electron output ani amp work like power circuit batteri thi use\n",
      "sci.med: skeptic pitt edu good geb problem gordon bank veri treatment gordon studi time peopl infect drug ani think like know use msg caus ha food medic patient diseas effect doctor wa thi\n",
      "sci.space: say develop hst rocket engin thing ha time project lunar solar spacecraft sky know cost think year use satellit like mission earth shuttl moon nasa launch wa thi orbit space\n",
      "soc.religion.christian: becaus love book like belief come onli doe homosexu word make ha mean whi faith know christ think sin peopl bibl believ church hi say jesu wa thi christian god\n",
      "talk.politics.guns: hi time whi bd polic crimin know ha shoot use state crime kill ani say like koresh govern firearm make think right batf fbi weapon law peopl thi wa gun\n",
      "talk.politics.mideast: attack time ani greek turk think peac make countri nation govern palestinian right ha hi jewish state turkish war kill say muslim peopl thi jew isra arab wa armenian israel\n",
      "talk.politics.misc: time american becaus health year ani whi children know sex insur want law ha clinton men presid state make like think govern right tax gay say homosexu wa peopl thi\n",
      "talk.religion.misc: theori good fbi bibl context start claim point children rosicrucian peopl make word mean know believ evid hi jesu think moral koresh say god cheer thi christian cheer kent wa kent\n"
     ]
    }
   ],
   "source": [
    "show_topK(em_nb_clf, vectorizer, category_names, K=30) # keywords for each class by semisupervised EM NB classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
